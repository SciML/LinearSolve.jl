<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Accelerating your Linear Solves · LinearSolve.jl</title><meta name="title" content="Accelerating your Linear Solves · LinearSolve.jl"/><meta property="og:title" content="Accelerating your Linear Solves · LinearSolve.jl"/><meta property="twitter:title" content="Accelerating your Linear Solves · LinearSolve.jl"/><meta name="description" content="Documentation for LinearSolve.jl."/><meta property="og:description" content="Documentation for LinearSolve.jl."/><meta property="twitter:description" content="Documentation for LinearSolve.jl."/><meta property="og:url" content="https://docs.sciml.ai/LinearSolve/stable/tutorials/accelerating_choices/"/><meta property="twitter:url" content="https://docs.sciml.ai/LinearSolve/stable/tutorials/accelerating_choices/"/><link rel="canonical" href="https://docs.sciml.ai/LinearSolve/stable/tutorials/accelerating_choices/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="LinearSolve.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">LinearSolve.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">LinearSolve.jl: High-Performance Unified Linear Solvers</a></li><li><a class="tocitem" href="../linear/">Getting Started with Solving Linear Systems in Julia</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../caching_interface/">Linear Solve with Caching Interface</a></li><li class="is-active"><a class="tocitem" href>Accelerating your Linear Solves</a><ul class="internal"><li><a class="tocitem" href="#Understanding-Performance-of-Dense-Linear-Solves"><span>Understanding Performance of Dense Linear Solves</span></a></li><li><a class="tocitem" href="#Understanding-Performance-of-Sparse-Linear-Solves"><span>Understanding Performance of Sparse Linear Solves</span></a></li></ul></li><li><a class="tocitem" href="../gpu/">GPU-Accelerated Linear Solving in Julia</a></li><li><a class="tocitem" href="../autotune/">Automatic Algorithm Selection with LinearSolveAutotune</a></li></ul></li><li><span class="tocitem">Basics</span><ul><li><a class="tocitem" href="../../basics/LinearProblem/">Linear Problems</a></li><li><a class="tocitem" href="../../basics/algorithm_selection/">Algorithm Selection Guide</a></li><li><a class="tocitem" href="../../basics/common_solver_opts/">Common Solver Options (Keyword Arguments for Solve)</a></li><li><a class="tocitem" href="../../basics/OperatorAssumptions/">Linear Solve Operator Assumptions</a></li><li><a class="tocitem" href="../../basics/Preconditioners/">Preconditioners</a></li><li><a class="tocitem" href="../../basics/FAQ/">Frequently Asked Questions</a></li></ul></li><li><span class="tocitem">Solvers</span><ul><li><a class="tocitem" href="../../solvers/solvers/">Linear System Solvers</a></li></ul></li><li><span class="tocitem">Advanced</span><ul><li><a class="tocitem" href="../../advanced/developing/">Developing New Linear Solvers</a></li><li><a class="tocitem" href="../../advanced/custom/">Passing in a Custom Linear Solver</a></li><li><a class="tocitem" href="../../advanced/internal_api/">Internal API Documentation</a></li></ul></li><li><a class="tocitem" href="../../release_notes/">Release Notes</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>Accelerating your Linear Solves</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Accelerating your Linear Solves</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/SciML/LinearSolve.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/SciML/LinearSolve.jl/blob/main/docs/src/tutorials/accelerating_choices.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Accelerating-your-Linear-Solves"><a class="docs-heading-anchor" href="#Accelerating-your-Linear-Solves">Accelerating your Linear Solves</a><a id="Accelerating-your-Linear-Solves-1"></a><a class="docs-heading-anchor-permalink" href="#Accelerating-your-Linear-Solves" title="Permalink"></a></h1><div class="admonition is-info" id="Note-412f2be6ead215e0"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-412f2be6ead215e0" title="Permalink"></a></header><div class="admonition-body"><p>This section is essential if you wish to achieve maximum performance with LinearSolve.jl, especially on v7 and above. Please ensure the tips of this section are adhered to when optimizing code and benchmarking.</p></div></div><p>Great, you&#39;ve learned how to use LinearSolve.jl and you&#39;re using it daily, either directly or through other SciML libraries, and you want to improve your performance. How can this be done? While it might seem at first like a hopeless endeavour, &quot;A\b uses a BLAS library and so it&#39;s already highly optimized C code&quot;, it turns out there are many factors you need to consider to squeeze out the last 10x of performance. And yes, it can be about a factor of 10 in some scenarios, so let&#39;s dive in.</p><h2 id="Understanding-Performance-of-Dense-Linear-Solves"><a class="docs-heading-anchor" href="#Understanding-Performance-of-Dense-Linear-Solves">Understanding Performance of Dense Linear Solves</a><a id="Understanding-Performance-of-Dense-Linear-Solves-1"></a><a class="docs-heading-anchor-permalink" href="#Understanding-Performance-of-Dense-Linear-Solves" title="Permalink"></a></h2><p>The performance of dense linear solvers is highly dependent on the size of the matrix and the chosen architecture to run on, i.e. the CPU. <a href="https://github.com/SciML/LinearSolve.jl/issues/357">This issue</a> gathered benchmark data from many different users and is summarized in the following graphs:</p><p><img src="../../assets/dense_linear_solves.png" alt="Dense Linear Solve Benchmarks"/></p><p>Now one thing that is immediate is for example that AppleAccelerate generally does well on Apple M-series chips, MKL generally does well on Intel, etc. And we know this in LinearSolve.jl, in fact we automatically default to different BLASes based on the CPU architecture already as part of the design! So that covers most of the variation, but there are a few major tips to note when fine tuning the results to your system:</p><ol><li>One of the best methods for size 150x150 matrices and below is RecursiveFactorization.jl. This is a pure Julia BLAS system, but it has a high load time overhead, and thus as of v7 it&#39;s no longer loaded by default! Thus if your matrices are in this range and you would value better run times at the cost of compile and load times, it is recommended you add <code>using RecursiveFactorization</code>. The defaulting algorithm will then consider it in its list and will automatically (in an architecture-specific way) insert it as it feels necessary.</li><li>One of the major factors that can inhibit BLAS performance on LU factorization is multithreading. In many of these plots you can see a giant dip in GFLOPs (higher is better) when a certain size threshold is hit. This is because, for the number of chosen threads, there was not enough work and thus when the threading threshold is hit you get a hit to the performance due to the added overhead. The threading performance can be a per-system thing, and it can be greatly influenced by the number of cores on your system and the number of threads you allow. Thus for example, OpenBLAS&#39; LU factorization seems to generally be really bad at guessing the thread switch point for CPUs with really high core/thread counts. If this is the case, you may want to investigate decreasing your number of BLAS threads, i.e. via <code>BLAS.set_num_threads(i)</code>. Note that RecursiveFactorization.jl uses your Julia thread pool instead of the BLAS threads.</li><li>The switch points between algorithms can be fairly inexact. LinearSolve.jl tried to keep a tab on where they are per platform and keep updated, but it can be a moving battle. You may be able to eek out some performance by testing between the various options on your platform, i.e. RFLUFactorization vs LUFactorization vs AppleAccelerateLUFactorization (M-series) vs MKLFactorization (X86) and hardcoding the choice for your problem if the default did not make the right guess.</li></ol><div class="admonition is-category-warn" id="Warn-a9b2c32ba69415f2"><header class="admonition-header">Warn<a class="admonition-anchor" href="#Warn-a9b2c32ba69415f2" title="Permalink"></a></header><div class="admonition-body"><p>As noted, RecursiveFactorization.jl is one of the fastest linear solvers for smaller dense matrices but requires <code>using RecursiveFactorization</code> in order to be used in the default solver setups! Thus it&#39;s recommended that any optimized code or benchmarks sets this up.</p></div></div><h2 id="Understanding-Performance-of-Sparse-Linear-Solves"><a class="docs-heading-anchor" href="#Understanding-Performance-of-Sparse-Linear-Solves">Understanding Performance of Sparse Linear Solves</a><a id="Understanding-Performance-of-Sparse-Linear-Solves-1"></a><a class="docs-heading-anchor-permalink" href="#Understanding-Performance-of-Sparse-Linear-Solves" title="Permalink"></a></h2><p>Sparse linear solvers are not as dependent on the CPU but highly dependent on the problem that is being solved. For example, this is for a 1D laplacian vs a 3D laplacian, changing N to make smaller and bigger versions:</p><p><img src="../../assets/sparse_linear_solves.png" alt="Sparse Linear Solve Benchmarks"/></p><p>Notice that the optimal linear solver changes based on problem (i.e. sparsity pattern) and size. LinearSolve.jl just uses a very simple &quot;if small then use KLU and if large use UMFPACK&quot;, which is validated by this plot, but leaves a lot to be desired. In particular, the following rules should be thought about:</p><ol><li>Pardiso is a great solver, you should try <code>using Pardiso</code> and using <code>MKLPardiso()</code> in many scenarios.</li><li>The more structured a sparsity pattern is, the worse KLU is in comparison to the other algorithms.</li><li>A Krylov subspace method with proper preconditioning will be better than direct solvers when the matrices get large enough. You could always precondition a sparse matrix with iLU as an easy choice, though the tolerance would need to be tuned in a problem-specific way. Please see the <a href="https://docs.sciml.ai/LinearSolve/stable/basics/Preconditioners/">preconditioenrs page</a> for more information on defining and using preconditioners.</li></ol><div class="admonition is-info" id="Note-f74a80697b6761a6"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-f74a80697b6761a6" title="Permalink"></a></header><div class="admonition-body"><p>UMFPACK does better when the BLAS is not OpenBLAS. Try <code>using MKL</code> on Intel and AMD Ryzen platforms and UMPACK will be faster! LinearSolve.jl cannot default to this as this changes global settings and thus only defaults to MKL locally, and thus cannot change the setting within UMFPACK.</p></div></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../caching_interface/">« Linear Solve with Caching Interface</a><a class="docs-footer-nextpage" href="../gpu/">GPU-Accelerated Linear Solving in Julia »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.15.0 on <span class="colophon-date" title="Thursday 30 October 2025 20:55">Thursday 30 October 2025</span>. Using Julia version 1.12.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
