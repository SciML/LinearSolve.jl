<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Linear System Solvers · LinearSolve.jl</title><script async src="https://www.googletagmanager.com/gtag/js?id=UA-90474609-3"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-90474609-3', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://linearsolve.sciml.ai/stable/solvers/solvers/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="LinearSolve.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">LinearSolve.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">LinearSolve.jl: High-Performance Unified Linear Solvers</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../tutorials/linear/">Solving Linear Systems in Julia</a></li><li><a class="tocitem" href="../../tutorials/caching_interface/">Linear Solve with Caching Interface</a></li></ul></li><li><span class="tocitem">Basics</span><ul><li><a class="tocitem" href="../../basics/LinearProblem/">Linear Problems</a></li><li><a class="tocitem" href="../../basics/common_solver_opts/">Common Solver Options (Keyword Arguments for Solve)</a></li><li><a class="tocitem" href="../../basics/CachingAPI/">Caching Interface API Functions</a></li><li><a class="tocitem" href="../../basics/Preconditioners/">Preconditioners</a></li><li><a class="tocitem" href="../../basics/FAQ/">Frequently Asked Questions</a></li></ul></li><li><span class="tocitem">Solvers</span><ul><li class="is-active"><a class="tocitem" href>Linear System Solvers</a><ul class="internal"><li><a class="tocitem" href="#Recommended-Methods"><span>Recommended Methods</span></a></li><li><a class="tocitem" href="#Full-List-of-Methods"><span>Full List of Methods</span></a></li></ul></li></ul></li><li><span class="tocitem">Advanced</span><ul><li><a class="tocitem" href="../../advanced/developing/">Developing New Linear Solvers</a></li><li><a class="tocitem" href="../../advanced/custom/">Passing in a Custom Linear Solver</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Solvers</a></li><li class="is-active"><a href>Linear System Solvers</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Linear System Solvers</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/SciML/LinearSolve.jl/blob/main/docs/src/solvers/solvers.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="linearsystemsolvers"><a class="docs-heading-anchor" href="#linearsystemsolvers">Linear System Solvers</a><a id="linearsystemsolvers-1"></a><a class="docs-heading-anchor-permalink" href="#linearsystemsolvers" title="Permalink"></a></h1><p><code>solve(prob::LinearProlem,alg;kwargs)</code></p><p>Solves for <span>$Au=b$</span> in the problem defined by <code>prob</code> using the algorithm <code>alg</code>. If no algorithm is given, a default algorithm will be chosen.</p><h2 id="Recommended-Methods"><a class="docs-heading-anchor" href="#Recommended-Methods">Recommended Methods</a><a id="Recommended-Methods-1"></a><a class="docs-heading-anchor-permalink" href="#Recommended-Methods" title="Permalink"></a></h2><p>The default algorithm <code>nothing</code> is good for choosing an algorithm that will work, but one may need to change this to receive more performance or precision. If more precision is necessary, <code>QRFactorization()</code> and <code>SVDFactorization()</code> are the best choices, with SVD being the slowest but most precise.</p><p>For efficiency, <code>RFLUFactorization</code> is the fastest for dense LU-factorizations. <code>FastLUFactorization</code> will be faster than <code>LUFactorization</code> which is the Base.LinearAlgebra (<code>\</code> default) implementation of LU factorization. <code>SimpleLUFactorization</code> will be fast on very small matrices.</p><p>For sparse LU-factorizations, <code>KLUFactorization</code> if there is less structure to the sparsity pattern and <code>UMFPACKFactorization</code> if there is more structure. Pardiso.jl&#39;s methods are also known to be very efficient sparse linear solvers.</p><p>As sparse matrices get larger, iterative solvers tend to get more efficient than factorization methods if a lower tolerance of the solution is required.</p><p>Krylov.jl generally outperforms IterativeSolvers.jl and KrylovKit.jl, and is compatible with CPUs and GPUs, and thus is the generally preferred form for Krylov methods.</p><p>Finally, a user can pass a custom function for handling the linear solve using <code>LinearSolveFunction()</code> if existing solvers are not optimally suited for their application. The interface is detailed <a href="#passing-in-a-custom-linear-solver">here</a></p><h2 id="Full-List-of-Methods"><a class="docs-heading-anchor" href="#Full-List-of-Methods">Full List of Methods</a><a id="Full-List-of-Methods-1"></a><a class="docs-heading-anchor-permalink" href="#Full-List-of-Methods" title="Permalink"></a></h2><h3 id="RecursiveFactorization.jl"><a class="docs-heading-anchor" href="#RecursiveFactorization.jl">RecursiveFactorization.jl</a><a id="RecursiveFactorization.jl-1"></a><a class="docs-heading-anchor-permalink" href="#RecursiveFactorization.jl" title="Permalink"></a></h3><ul><li><code>RFLUFactorization()</code>: a fast pure Julia LU-factorization implementation using RecursiveFactorization.jl. This is by far the fastest LU-factorization implementation, usually outperforming OpenBLAS and MKL, but currently optimized only for Base <code>Array</code> with <code>Float32</code> or <code>Float64</code>.  Additional optimization for  complex matrices is in the works.</li></ul><h3 id="Base.LinearAlgebra"><a class="docs-heading-anchor" href="#Base.LinearAlgebra">Base.LinearAlgebra</a><a id="Base.LinearAlgebra-1"></a><a class="docs-heading-anchor-permalink" href="#Base.LinearAlgebra" title="Permalink"></a></h3><p>These overloads tend to work for many array types, such as <code>CuArrays</code> for GPU-accelerated solving, using the overloads provided by the respective packages. Given that this can be customized per-package, details given below describe a subset of important arrays (<code>Matrix</code>, <code>SparseMatrixCSC</code>, <code>CuMatrix</code>, etc.)</p><ul><li><code>LUFactorization(pivot=LinearAlgebra.RowMaximum())</code>: Julia&#39;s built in <code>lu</code>.<ul><li>On dense matrices this uses the current BLAS implementation of the user&#39;s computer which by default is OpenBLAS but will use MKL if the user does <code>using MKL</code> in their system.</li><li>On sparse matrices this will use UMFPACK from SuiteSparse. Note that this will not cache the symbolic factorization.</li><li>On CuMatrix it will use a CUDA-accelerated LU from CuSolver.</li><li>On BandedMatrix and BlockBandedMatrix it will use a banded LU.</li></ul></li><li><code>QRFactorization(pivot=LinearAlgebra.NoPivot(),blocksize=16)</code>: Julia&#39;s built in <code>qr</code>.<ul><li>On dense matrices this uses the current BLAS implementation of the user&#39;s computer which by default is OpenBLAS but will use MKL if the user does <code>using MKL</code> in their system.</li><li>On sparse matrices this will use SPQR from SuiteSparse</li><li>On CuMatrix it will use a CUDA-accelerated QR from CuSolver.</li><li>On BandedMatrix and BlockBandedMatrix it will use a banded QR.</li></ul></li><li><code>SVDFactorization(full=false,alg=LinearAlgebra.DivideAndConquer())</code>: Julia&#39;s built in <code>svd</code>.<ul><li>On dense matrices this uses the current BLAS implementation of the user&#39;s computer which by default is OpenBLAS but will use MKL if the user does <code>using MKL</code> in their system.</li></ul></li><li><code>GenericFactorization(fact_alg)</code>: Constructs a linear solver from a generic factorization algorithm <code>fact_alg</code> which complies with the Base.LinearAlgebra factorization API. Quoting from Base:<ul><li>If <code>A</code> is upper or lower triangular (or diagonal), no factorization of <code>A</code> is required and the system is solved with either forward or backward substitution. For non-triangular square matrices, an LU factorization is used. For rectangular <code>A</code> the result is the minimum-norm least squares solution computed by a pivoted QR factorization of <code>A</code> and a rank estimate of <code>A</code> based on the R factor. When <code>A</code> is sparse, a similar polyalgorithm is used. For indefinite matrices, the <code>LDLt</code> factorization does not use pivoting during the numerical factorization and therefore the procedure can fail even for invertible matrices.</li></ul></li></ul><h3 id="LinearSolve.jl"><a class="docs-heading-anchor" href="#LinearSolve.jl">LinearSolve.jl</a><a id="LinearSolve.jl-1"></a><a class="docs-heading-anchor-permalink" href="#LinearSolve.jl" title="Permalink"></a></h3><p>LinearSolve.jl contains some linear solvers built in.</p><ul><li><code>SimpleLUFactorization</code>: a simple LU-factorization implementation without BLAS. Fast for small matrices.</li></ul><h3 id="FastLapackInterface.jl"><a class="docs-heading-anchor" href="#FastLapackInterface.jl">FastLapackInterface.jl</a><a id="FastLapackInterface.jl-1"></a><a class="docs-heading-anchor-permalink" href="#FastLapackInterface.jl" title="Permalink"></a></h3><p>FastLapackInterface.jl is a package that allows for a lower-level interface to the LAPACK calls to allow for preallocating workspaces to decrease the overhead of the wrappers. LinearSolve.jl provides a wrapper to these routines in a way where an initialized solver has a non-allocating LU factorization. In theory, this post-initialized solve should always be faster than the Base.LinearAlgebra version.</p><ul><li><code>FastLUFactorization</code> the <code>FastLapackInterface</code> version of the LU factorizaiton. Notably, this version does not allow for choice of pivoting method.</li><li><code>FastQRFactorization(pivot=NoPivot(),blocksize=32)</code>, the <code>FastLapackInterface</code> version of the QR factorizaiton.</li></ul><h3 id="SuiteSparse.jl"><a class="docs-heading-anchor" href="#SuiteSparse.jl">SuiteSparse.jl</a><a id="SuiteSparse.jl-1"></a><a class="docs-heading-anchor-permalink" href="#SuiteSparse.jl" title="Permalink"></a></h3><p>By default, the SuiteSparse.jl are implemented for efficiency by caching the symbolic factorization. I.e. if <code>set_A</code> is used, it is expected that the new <code>A</code> has the same sparsity pattern as the previous <code>A</code>. If this algorithm is to be used in a context where that assumption does not hold, set <code>reuse_symbolic=false</code>.</p><ul><li><code>KLUFactorization(;reuse_symbolic=true)</code>: A fast sparse LU-factorization which specializes on sparsity patterns with &quot;less structure&quot;.</li><li><code>UMFPACKFactorization(;reuse_symbolic=true)</code>: A fast sparse multithreaded LU-factorization which specializes on sparsity patterns that are more structured.</li></ul><h3 id="Pardiso.jl"><a class="docs-heading-anchor" href="#Pardiso.jl">Pardiso.jl</a><a id="Pardiso.jl-1"></a><a class="docs-heading-anchor-permalink" href="#Pardiso.jl" title="Permalink"></a></h3><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Using this solver requires adding the package LinearSolvePardiso.jl</p></div></div><p>The following algorithms are pre-specified:</p><ul><li><code>MKLPardisoFactorize(;kwargs...)</code>: A sparse factorization method.</li><li><code>MKLPardisoIterate(;kwargs...)</code>: A mixed factorization+iterative method.</li></ul><p>Those algorithms are defined via:</p><pre><code class="language-julia hljs">MKLPardisoFactorize(;kwargs...) = PardisoJL(;fact_phase=Pardiso.NUM_FACT,
                                             solve_phase=Pardiso.SOLVE_ITERATIVE_REFINE,
                                             kwargs...)
MKLPardisoIterate(;kwargs...) = PardisoJL(;solve_phase=Pardiso.NUM_FACT_SOLVE_REFINE,
                                           kwargs...)</code></pre><p>The full set of keyword arguments for <code>PardisoJL</code> are:</p><pre><code class="language-julia hljs">Base.@kwdef struct PardisoJL &lt;: SciMLLinearSolveAlgorithm
    nprocs::Union{Int, Nothing} = nothing
    solver_type::Union{Int, Pardiso.Solver, Nothing} = nothing
    matrix_type::Union{Int, Pardiso.MatrixType, Nothing} = nothing
    fact_phase::Union{Int, Pardiso.Phase, Nothing} = nothing
    solve_phase::Union{Int, Pardiso.Phase, Nothing} = nothing
    release_phase::Union{Int, Nothing} = nothing
    iparm::Union{Vector{Tuple{Int,Int}}, Nothing} = nothing
    dparm::Union{Vector{Tuple{Int,Int}}, Nothing} = nothing
end</code></pre><h3 id="CUDA.jl"><a class="docs-heading-anchor" href="#CUDA.jl">CUDA.jl</a><a id="CUDA.jl-1"></a><a class="docs-heading-anchor-permalink" href="#CUDA.jl" title="Permalink"></a></h3><p>Note that <code>CuArrays</code> are supported by <code>GenericFactorization</code> in the &quot;normal&quot; way. The following are non-standard GPU factorization routines.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Using this solver requires adding the package LinearSolveCUDA.jl</p></div></div><ul><li><code>CudaOffloadFactorization()</code>: An offloading technique used to GPU-accelerate CPU-based computations. Requires a sufficiently large <code>A</code> to overcome the data transfer costs.</li></ul><h3 id="IterativeSolvers.jl"><a class="docs-heading-anchor" href="#IterativeSolvers.jl">IterativeSolvers.jl</a><a id="IterativeSolvers.jl-1"></a><a class="docs-heading-anchor-permalink" href="#IterativeSolvers.jl" title="Permalink"></a></h3><ul><li><code>IterativeSolversJL_CG(args...;kwargs...)</code>: A generic CG implementation</li><li><code>IterativeSolversJL_GMRES(args...;kwargs...)</code>: A generic GMRES implementation</li><li><code>IterativeSolversJL_BICGSTAB(args...;kwargs...)</code>: A generic BICGSTAB implementation</li><li><code>IterativeSolversJL_MINRES(args...;kwargs...)</code>: A generic MINRES implementation</li></ul><p>The general algorithm is:</p><pre><code class="language-julia hljs">IterativeSolversJL(args...;
                   generate_iterator = IterativeSolvers.gmres_iterable!,
                   Pl=nothing, Pr=nothing,
                   gmres_restart=0, kwargs...)</code></pre><h3 id="Krylov.jl"><a class="docs-heading-anchor" href="#Krylov.jl">Krylov.jl</a><a id="Krylov.jl-1"></a><a class="docs-heading-anchor-permalink" href="#Krylov.jl" title="Permalink"></a></h3><ul><li><code>KrylovJL_CG(args...;kwargs...)</code>: A generic CG implementation</li><li><code>KrylovJL_GMRES(args...;kwargs...)</code>: A generic GMRES implementation</li><li><code>KrylovJL_BICGSTAB(args...;kwargs...)</code>: A generic BICGSTAB implementation</li><li><code>KrylovJL_MINRES(args...;kwargs...)</code>: A generic MINRES implementation</li></ul><p>The general algorithm is:</p><pre><code class="language-julia hljs">KrylovJL(args...; KrylovAlg = Krylov.gmres!,
                  Pl=nothing, Pr=nothing,
                  gmres_restart=0, window=0,
                  kwargs...)</code></pre><h3 id="KrylovKit.jl"><a class="docs-heading-anchor" href="#KrylovKit.jl">KrylovKit.jl</a><a id="KrylovKit.jl-1"></a><a class="docs-heading-anchor-permalink" href="#KrylovKit.jl" title="Permalink"></a></h3><ul><li><code>KrylovKitJL_CG(args...;kwargs...)</code>: A generic CG implementation</li><li><code>KrylovKitJL_GMRES(args...;kwargs...)</code>: A generic GMRES implementation</li></ul><p>The general algorithm is:</p><pre><code class="language-julia hljs">function KrylovKitJL(args...;
                     KrylovAlg = KrylovKit.GMRES, gmres_restart = 0,
                     kwargs...)</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../basics/FAQ/">« Frequently Asked Questions</a><a class="docs-footer-nextpage" href="../../advanced/developing/">Developing New Linear Solvers »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.23 on <span class="colophon-date" title="Thursday 6 October 2022 07:58">Thursday 6 October 2022</span>. Using Julia version 1.8.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
