<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>GPU-Accelerated Linear Solving in Julia · LinearSolve.jl</title><meta name="title" content="GPU-Accelerated Linear Solving in Julia · LinearSolve.jl"/><meta property="og:title" content="GPU-Accelerated Linear Solving in Julia · LinearSolve.jl"/><meta property="twitter:title" content="GPU-Accelerated Linear Solving in Julia · LinearSolve.jl"/><meta name="description" content="Documentation for LinearSolve.jl."/><meta property="og:description" content="Documentation for LinearSolve.jl."/><meta property="twitter:description" content="Documentation for LinearSolve.jl."/><meta property="og:url" content="https://docs.sciml.ai/LinearSolve/stable/tutorials/gpu/"/><meta property="twitter:url" content="https://docs.sciml.ai/LinearSolve/stable/tutorials/gpu/"/><link rel="canonical" href="https://docs.sciml.ai/LinearSolve/stable/tutorials/gpu/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="LinearSolve.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">LinearSolve.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">LinearSolve.jl: High-Performance Unified Linear Solvers</a></li><li><a class="tocitem" href="../linear/">Getting Started with Solving Linear Systems in Julia</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../caching_interface/">Linear Solve with Caching Interface</a></li><li><a class="tocitem" href="../accelerating_choices/">Accelerating your Linear Solves</a></li><li class="is-active"><a class="tocitem" href>GPU-Accelerated Linear Solving in Julia</a><ul class="internal"><li><a class="tocitem" href="#GPU-Offloading"><span>GPU-Offloading</span></a></li><li><a class="tocitem" href="#GPUArray-Interface"><span>GPUArray Interface</span></a></li><li><a class="tocitem" href="#Sparse-Matrices-on-GPUs"><span>Sparse Matrices on GPUs</span></a></li></ul></li></ul></li><li><span class="tocitem">Basics</span><ul><li><a class="tocitem" href="../../basics/LinearProblem/">Linear Problems</a></li><li><a class="tocitem" href="../../basics/common_solver_opts/">Common Solver Options (Keyword Arguments for Solve)</a></li><li><a class="tocitem" href="../../basics/OperatorAssumptions/">Linear Solve Operator Assumptions</a></li><li><a class="tocitem" href="../../basics/Preconditioners/">Preconditioners</a></li><li><a class="tocitem" href="../../basics/FAQ/">Frequently Asked Questions</a></li></ul></li><li><span class="tocitem">Solvers</span><ul><li><a class="tocitem" href="../../solvers/solvers/">Linear System Solvers</a></li></ul></li><li><span class="tocitem">Advanced</span><ul><li><a class="tocitem" href="../../advanced/developing/">Developing New Linear Solvers</a></li><li><a class="tocitem" href="../../advanced/custom/">Passing in a Custom Linear Solver</a></li></ul></li><li><a class="tocitem" href="../../release_notes/">Release Notes</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>GPU-Accelerated Linear Solving in Julia</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>GPU-Accelerated Linear Solving in Julia</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/SciML/LinearSolve.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/SciML/LinearSolve.jl/blob/main/docs/src/tutorials/gpu.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="GPU-Accelerated-Linear-Solving-in-Julia"><a class="docs-heading-anchor" href="#GPU-Accelerated-Linear-Solving-in-Julia">GPU-Accelerated Linear Solving in Julia</a><a id="GPU-Accelerated-Linear-Solving-in-Julia-1"></a><a class="docs-heading-anchor-permalink" href="#GPU-Accelerated-Linear-Solving-in-Julia" title="Permalink"></a></h1><p>LinearSolve.jl provides two ways to GPU accelerate linear solves:</p><ul><li>Offloading: offloading takes a CPU-based problem and automatically transforms it into a GPU-based problem in the background, and returns the solution on CPU. Thus using offloading requires no change on the part of the user other than to choose an offloading solver.</li><li>Array type interface: the array type interface requires that the user defines the <code>LinearProblem</code> using an <code>AbstractGPUArray</code> type and chooses an appropriate solver (or uses the default solver). The solution will then be returned as a GPU array type.</li></ul><p>The offloading approach has the advantage of being simpler and requiring no change to existing CPU code, while having the disadvantage of having more overhead. In the following sections we will demonstrate how to use each of the approaches.</p><div class="admonition is-category-warn" id="Warn-99761867ffa99d1f"><header class="admonition-header">Warn<a class="admonition-anchor" href="#Warn-99761867ffa99d1f" title="Permalink"></a></header><div class="admonition-body"><p>GPUs are not always faster! Your matrices need to be sufficiently large in order for GPU accelerations to actually be faster. For offloading it&#39;s around 1,000 x 1,000 matrices and for Array type interface it&#39;s around 100 x 100. For sparse matrices, it is highly dependent on the sparsity pattern and the amount of fill-in.</p></div></div><h2 id="GPU-Offloading"><a class="docs-heading-anchor" href="#GPU-Offloading">GPU-Offloading</a><a id="GPU-Offloading-1"></a><a class="docs-heading-anchor-permalink" href="#GPU-Offloading" title="Permalink"></a></h2><p>GPU offloading is simple as it&#39;s done simply by changing the solver algorithm. Take the example from the start of the documentation:</p><pre><code class="language-julia hljs">using LinearSolve

A = rand(4, 4)
b = rand(4)
prob = LinearProblem(A, b)
sol = solve(prob)
sol.u</code></pre><p>This computation can be moved to the GPU by the following:</p><pre><code class="language-julia hljs">using CUDA # Add the GPU library
sol = solve(prob, CudaOffloadFactorization())
sol.u</code></pre><h2 id="GPUArray-Interface"><a class="docs-heading-anchor" href="#GPUArray-Interface">GPUArray Interface</a><a id="GPUArray-Interface-1"></a><a class="docs-heading-anchor-permalink" href="#GPUArray-Interface" title="Permalink"></a></h2><p>For more manual control over the factorization setup, you can use the <a href="https://juliagpu.github.io/GPUArrays.jl/dev/">GPUArray interface</a>, the most common instantiation being <a href="https://cuda.juliagpu.org/stable/usage/array/">CuArray for CUDA-based arrays on NVIDIA GPUs</a>. To use this, we simply send the matrix <code>A</code> and the value <code>b</code> over to the GPU and solve:</p><pre><code class="language-julia hljs">using CUDA

A = rand(4, 4) |&gt; cu
b = rand(4) |&gt; cu
prob = LinearProblem(A, b)
sol = solve(prob)
sol.u</code></pre><pre><code class="nohighlight hljs">4-element CuArray{Float32, 1, CUDA.DeviceMemory}:
 -27.02665
  16.338171
 -77.650116
 106.335686</code></pre><p>Notice that the solution is a <code>CuArray</code>, and thus one must use <code>Array(sol.u)</code> if you with to return it to the CPU. This setup does no automated memory transfers and will thus only move things to CPU on command.</p><div class="admonition is-category-warn" id="Warn-8197c0da4e098d6c"><header class="admonition-header">Warn<a class="admonition-anchor" href="#Warn-8197c0da4e098d6c" title="Permalink"></a></header><div class="admonition-body"><p>Many GPU functionalities, such as <code>CUDA.cu</code>, have a built-in preference for <code>Float32</code>. Generally it is much faster to use 32-bit floating point operations on GPU than 64-bit operations, and thus this is generally the right choice if going to such platforms. However, this change in numerical precision needs to be accounted for in your mathematics as it could lead to instabilities. To disable this, use a constructor that is more specific about the bitsize, such as <code>CuArray{Float64}(A)</code>. Additionally, preferring more stable factorization methods, such as <code>QRFactorization()</code>, can improve the numerics in such cases.</p></div></div><p>Similarly to other use cases, you can choose the solver, for example:</p><pre><code class="language-julia hljs">sol = solve(prob, QRFactorization())</code></pre><h2 id="Sparse-Matrices-on-GPUs"><a class="docs-heading-anchor" href="#Sparse-Matrices-on-GPUs">Sparse Matrices on GPUs</a><a id="Sparse-Matrices-on-GPUs-1"></a><a class="docs-heading-anchor-permalink" href="#Sparse-Matrices-on-GPUs" title="Permalink"></a></h2><p>Currently, sparse matrix computations on GPUs are only supported for CUDA. This is done using the <code>CUDA.CUSPARSE</code> sublibrary.</p><pre><code class="language-julia hljs">using LinearAlgebra, CUDA.CUSPARSE
T = Float32
n = 100
A_cpu = sprand(T, n, n, 0.05) + I
x_cpu = zeros(T, n)
b_cpu = rand(T, n)

A_gpu_csr = CuSparseMatrixCSR(A_cpu)
b_gpu = CuVector(b_cpu)</code></pre><p>In order to solve such problems using a direct method, you must add <a href="https://github.com/exanauts/CUDSS.jl">CUDSS.jl</a>. This looks like:</p><pre><code class="language-julia hljs">using CUDSS
sol = solve(prob, LUFactorization())</code></pre><div class="admonition is-info" id="Note-608f5fd40889ab03"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-608f5fd40889ab03" title="Permalink"></a></header><div class="admonition-body"><p>For now, CUDSS only supports CuSparseMatrixCSR type matrices.</p></div></div><p>Note that <code>KrylovJL</code> methods also work with sparse GPU arrays:</p><pre><code class="language-julia hljs">sol = solve(prob, KrylovJL_GMRES())</code></pre><p>Note that CUSPARSE also has some GPU-based preconditioners, such as a built-in <code>ilu</code>. However:</p><pre><code class="language-julia hljs">sol = solve(prob, KrylovJL_GMRES(precs = (A, p) -&gt; (CUDA.CUSPARSE.ilu02!(A, &#39;O&#39;), I)))</code></pre><p>However, right now CUSPARSE is missing the right <code>ldiv!</code> implementation for this to work in general. See https://github.com/SciML/LinearSolve.jl/issues/341 for details.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../accelerating_choices/">« Accelerating your Linear Solves</a><a class="docs-footer-nextpage" href="../../basics/LinearProblem/">Linear Problems »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Thursday 17 July 2025 23:50">Thursday 17 July 2025</span>. Using Julia version 1.11.6.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
